import os
import json
from dotenv import load_dotenv, find_dotenv
from src.utils.xfyun_chat import XFYunChat
from src.utils.resume_parser import *
from datetime import datetime

relate_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

FEEDBACK_FOLDER = os.path.join(relate_path, 'data/json/resume_analyse')
os.makedirs(FEEDBACK_FOLDER, exist_ok=True)

class ResumeOptimizer:
    def __init__(self, role: str,job_description: str = None):
        self.role = role
        self.job_description = job_description
        # self.system_prompt = f"""
        #     ä½ æ˜¯ä¸€åäººåŠ›èµ„æºä¸“å®¶ï¼Œæ“…é•¿ä»æŠ€æœ¯å²—ä½è§’åº¦å’ŒHRå²—ä½è§’åº¦ç»™å‡ºç®€å†ä¼˜åŒ–å»ºè®®ã€‚è¯·åŸºäºå€™é€‰äººçš„ç®€å†å†…å®¹ï¼Œé’ˆå¯¹â€œ{self.role}â€å²—ä½ï¼ŒæŒ‡å‡ºä»¥ä¸‹å‡ ç‚¹ï¼š
        #     1. ç®€å†ä¸­æœ‰å“ªäº›äº®ç‚¹ï¼›
        #     2. å“ªäº›å†…å®¹å¯ä»¥è¡¥å……æˆ–å¼ºåŒ–ï¼›
        #     3. ç”¨è¯­æ˜¯å¦ä¸“ä¸šã€æ¸…æ™°ï¼›
        #     4. ç»™å‡º3æ¡å…·ä½“ä¿®æ”¹å»ºè®®ã€‚
        #     è¯·ç”¨ä¸­æ–‡è¾“å‡ºå»ºè®®ã€‚
        # """
        self.system_prompt = """\
        ä½ æ˜¯ä¸€ä½èµ„æ·± HR é¡¾é—®ä¸æŠ€æœ¯ä¸“å®¶ï¼Œå°†å¯¹å€™é€‰äººçš„ç®€å†è¿›è¡Œç»“æ„åŒ–è¯„ä¼°ã€‚ä½ å°†è·å¾—ä»¥ä¸‹ä¸‰éƒ¨åˆ†ä¿¡æ¯ï¼š

        1. å€™é€‰äººç®€å†åŸæ–‡ï¼ˆCV å†…å®¹ï¼‰  
        2. ç›®æ ‡å²—ä½åç§°  
        3. å²—ä½èŒè´£ä¸è¦æ±‚ï¼ˆJD æè¿°ï¼‰

        ä½ çš„ä»»åŠ¡æ˜¯ä»ä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢å¯¹å€™é€‰äººè¿›è¡Œåˆ†æï¼Œå¹¶è¾“å‡º**ç»“æ„åŒ– JSON æ ¼å¼**ç»“æœã€‚

        ---

        ã€åˆ†æä»»åŠ¡ã€‘

        ä¸€ã€å²—ä½åŒ¹é…åº¦åˆ†æï¼ˆmatching_scoresï¼‰  
        è¯·åˆ†åˆ«å¯¹ä¸‹åˆ—ä¸‰ä¸ªç»´åº¦è¯„åˆ†ï¼Œæ¯ä¸ªç»´åº¦ä¸‹æœ‰ä¸‰ä¸ªå­é¡¹ï¼š

        1. æŠ€èƒ½åŒ¹é…åº¦ï¼ˆskills_matchï¼‰
           - æ ¸å¿ƒæŠ€èƒ½åŒ¹é…ï¼ˆcore_skillsï¼‰  
           - æŠ€æœ¯æ ˆè¦†ç›–ï¼ˆtech_stackï¼‰  
           - é¡¹ç›®ç»éªŒç›¸å…³æ€§ï¼ˆproject_relevanceï¼‰

        2. ç»éªŒä¸èƒŒæ™¯å¥‘åˆåº¦ï¼ˆexperience_matchï¼‰
           - å·¥ä½œå¹´é™åŒ¹é…ï¼ˆyears_fitï¼‰  
           - é¡¹ç›®è§„æ¨¡å¤æ‚åº¦ï¼ˆproject_scaleï¼‰  
           - è¡Œä¸šèƒŒæ™¯é€‚é…æ€§ï¼ˆindustry_fitï¼‰

        3. èŒä¸šå‘å±•å¥‘åˆåº¦ï¼ˆcareer_fitï¼‰
           - èŒä¸šè·¯å¾„ä¸€è‡´æ€§ï¼ˆcareer_pathï¼‰  
           - æˆé•¿æ½œåŠ›ï¼ˆgrowth_potentialï¼‰  
           - èŒä¸šç¨³å®šæ€§ï¼ˆstabilityï¼‰

        æ¯ä¸ªå­é¡¹å’Œæ€»é¡¹è¯·ç»™å‡ºï¼š
        - `score`ï¼ˆ0-100 æ•´æ•°ï¼‰
        - `comments`ï¼ˆç®€æ´è¯„è¯­ç»„æˆçš„å­—ç¬¦ä¸²æ•°ç»„ï¼‰

        ---

        äºŒã€ç®€å†ä¼˜åŒ–å»ºè®®ï¼ˆresume_optimizationï¼‰

        è¯·è¾“å‡ºä»¥ä¸‹å­—æ®µï¼š
        - `highlights`ï¼šç®€å†ä¸­å·²æœ‰äº®ç‚¹ï¼ˆå¦‚æŠ€èƒ½ã€ç»å†ã€å¥–é¡¹ï¼‰ï¼Œå­—ç¬¦ä¸²æ•°ç»„
        - `improvements_needed`ï¼šç¼ºå¤±æˆ–å¯è¡¥å……å†…å®¹ï¼ˆå¦‚é¡¹ç›®æˆæœç»†èŠ‚ï¼‰ï¼Œå­—ç¬¦ä¸²æ•°ç»„
        - `expression_suggestions`ï¼šè¡¨è¾¾æ–¹å¼å¯æ”¹è¿›ç‚¹ï¼ˆå¦‚æè¿°ä¸å¤Ÿå…·ä½“æˆ–æ ¼å¼é—®é¢˜ï¼‰ï¼Œå­—ç¬¦ä¸²æ•°ç»„

        ---

        ä¸‰ã€æœ€ç»ˆæ¨èå»ºè®®ï¼ˆfinal_recommendationï¼‰

        è¯·ç»™å‡ºï¼š
        - `decision`ï¼šä»…é™äº ["æ¨è", "å¾…å®š", "ä¸æ¨è"]
        - `key_reasons`ï¼šæ”¯æ’‘æ¨èåˆ¤æ–­çš„ç†ç”±ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰
        - `suggested_actions`ï¼šä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰

        ---

        ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘

        âš ï¸ è¯·ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹ JSON ç»“æ„ï¼Œå„å­—æ®µå‡ä¸å¾—çœç•¥ã€æ”¹åã€åˆå¹¶ã€åµŒå¥—é”™ä½ã€‚æ³¨æ„å­—æ®µåç§°å¿…é¡»ä¸ºè‹±æ–‡ï¼

        ```json
        {
          "matching_scores": {
            "skills_match": {
              "score": 0,
              "details": {
                "core_skills": 0,
                "tech_stack": 0,
                "project_relevance": 0
              },
              "comments": ["..."]
            },
            "experience_match": {
              "score": 0,
              "details": {
                "years_fit": 0,
                "project_scale": 0,
                "industry_fit": 0
              },
              "comments": ["..."]
            },
            "career_fit": {
              "score": 0,
              "details": {
                "career_path": 0,
                "growth_potential": 0,
                "stability": 0
              },
              "comments": ["..."]
            }
          },
          "overall_match": 0,
          "resume_optimization": {
            "highlights": ["..."],
            "improvements_needed": ["..."],
            "expression_suggestions": ["..."]
          },
          "final_recommendation": {
            "decision": "æ¨è",
            "key_reasons": ["..."],
            "suggested_actions": ["..."]
          }
        }
"""
        load_dotenv(os.path.join(os.path.dirname(os.getcwd()), ".env"))
        load_dotenv()
        self.resume_improve_model = XFYunChat(
            appid=os.getenv("XFYUN_APPID"),
            api_key=os.getenv("XFYUN_API_KEY"),
            api_secret=os.getenv("XFYUN_API_SECRET"),
            system_prompt=self.system_prompt
        )

    def save_result_as_json(self,feedback_path,feedback_data):
        # Get current timestamp to use in the file name
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = f"{timestamp}.json"
        file_path = os.path.join(feedback_path, file_name)

        # Write the JSON data into the file with UTF-8 encoding
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(feedback_data, f, ensure_ascii=False, indent=2)

        print(f"Result saved to: {file_path}")

    def optimize_resume(self, resume_dict: dict,name) -> str:
        resume_text = self._format_resume(resume_dict)
        # æ„å»ºè¾“å…¥å†…å®¹
        input_content = {
            "resume": resume_text,
            "job_role": self.role,
            "job_description": self.job_description
        }

        # æ‹¼æ¥ prompt
        full_prompt = f"""
        è¯·æ ¹æ®ä»¥ä¸‹ç®€å†å†…å®¹ã€ç›®æ ‡å²—ä½ã€å²—ä½èŒè´£è¿›è¡Œç»“æ„åŒ–è¯„ä¼°ï¼š

        ã€ç®€å†å†…å®¹ã€‘
        {resume_text}

        ã€ç›®æ ‡å²—ä½ã€‘
        {self.role}

        ã€å²—ä½èŒè´£ä¸è¦æ±‚ã€‘
        {self.job_description}

        è¯·æ ¹æ®ç³»ç»Ÿæç¤ºä¸­çš„æ ¼å¼è¦æ±‚å®Œæˆè¾“å‡ºã€‚
        """

        response = self.resume_improve_model.chat(full_prompt)
        if response is None:
            print("æ²¡æœ‰æ”¶åˆ°æ¨¡å‹çš„å“åº”ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–ç½‘ç»œè¿æ¥ã€‚")
            return None
        else:
            feedback_path = os.path.join(FEEDBACK_FOLDER, name)
            os.makedirs(feedback_path, exist_ok=True)
            self.save_result_as_json(feedback_path,response)
        print("ğŸ” ç®€å†ä¼˜åŒ–å»ºè®®ï¼š\n", response)
        # return self.parse_feedback_to_json(response)
        return response
    def _format_resume(self, resume_dict: dict) -> str:
        """å°† dict è½¬æ¢æˆæ ¼å¼æ¸…æ™°çš„æ–‡æœ¬ï¼Œä¾¿äº LLM ç†è§£"""
        parts = []
        for key, value in resume_dict.items():
            if isinstance(value, list):
                value_str = "\n  - " + "\n  - ".join(map(str, value))
            else:
                value_str = str(value)
            parts.append(f"{key}:\n{value_str}")
        return "\n\n".join(parts)

    def parse_feedback_to_json(self, text):
        """å°†åé¦ˆæ–‡æœ¬è§£æä¸ºJSONæ ¼å¼"""
        lines = text.strip().split('\n')
        feedback_data = []

        current_section = None
        current_points = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸»è¦åˆ†ç±»ï¼ˆ1. 2. 3.ï¼‰
            if line[0].isdigit() and line[1] == '.':
                # ä¿å­˜ä¹‹å‰çš„åˆ†ç±»
                if current_section:
                    feedback_data.append({
                        "point": current_section,
                        "content": current_points.copy()
                    })

                # å¼€å§‹æ–°åˆ†ç±»
                current_section = line[2:].strip().rstrip('ï¼š')
                current_points = []

            # æ£€æŸ¥æ˜¯å¦æ˜¯å­é¡¹ï¼ˆä»¥ - å¼€å¤´ï¼‰
            elif line.startswith('-'):
                point = line[1:].strip()
                current_points.append(point)

        # æ·»åŠ æœ€åä¸€ä¸ªåˆ†ç±»
        if current_section:
            feedback_data.append({
                "point": current_section,
                "content": current_points
            })

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = f"{timestamp}.json"
        file_path = os.path.join(FEEDBACK_FOLDER, file_name)

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(feedback_data, f, ensure_ascii=False, indent=2)

        return feedback_data

if __name__ == "__main__":
    json_path = r"D:\AllFiles\competition\soft\Screening-LLM\data\cvs\webå‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ-active.docx"
    name = "æ¨ç’é›¨"
    cv_json = parse_resume(json_path)
    role = "å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ"
    job_description = """
    èŒä½è¦æ±‚ï¼š
1ï¼ç†Ÿæ‚‰ HTTP åè®®ã€æµè§ˆå™¨æ¸²æŸ“åŸç†
2ï¼ç†Ÿæ‚‰HTML5/CSS3/JavaScriptï¼Œäº†è§£ES6ï¼‹æ–°ç‰¹æ€§
3ï¼ç†Ÿæ‚‰ React / Vue ç­‰å¸¸ç”¨å‰ç«¯æ¡†æ¶ï¼Œç†Ÿç»ƒä½¿ç”¨ Tailwind CSS å’Œ TypeScript 
4ï¼ç†Ÿæ‚‰ Vite ç­‰æ„å»ºå·¥å…·ï¼Œç†Ÿæ‚‰ NPM / Yarn åŒ…ç®¡ç†
5.ç†Ÿç»ƒä½¿ç”¨ Git è¿›è¡Œç‰ˆæœ¬æ§åˆ¶
åŠ åˆ†é¡¹ï¼š
1.ç†Ÿæ‚‰ Golang Gin Web åç«¯æ¡†æ¶å¼€å‘ä¼˜å…ˆ
2.ç†Ÿæ‚‰ Flutter è·¨ç«¯å¼€å‘å·¥å…·è€…ä¼˜å…ˆ
    """
    optimizer = ResumeOptimizer(role,job_description)
    advice = optimizer.optimize_resume(cv_json, name)
    # print(advice)
