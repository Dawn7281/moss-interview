import os
import time
import json
from dotenv import load_dotenv
from googlesearch import search
from src.utils.xfyun_chat import XFYunChat
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import re

# è®¾ç½®å…¨å±€ä»£ç†
os.environ["http_proxy"] = "http://127.0.0.1:7890"
os.environ["https_proxy"] = "http://127.0.0.1:7890"

# 1. è¯»å–.envä¸­çš„è®¯é£æ˜Ÿç«APIä¿¡æ¯
load_dotenv()
SPARK_API_KEY = os.getenv("XFYUN_API_KEY")
SPARK_API_SECRET = os.getenv("XFYUN_API_SECRET")
SPARK_APP_ID = os.getenv("XFYUN_APPID")

# 2. åˆå§‹åŒ–è®¯é£æ˜Ÿç«èŠå¤©å®ä¾‹
search_chat = XFYunChat(
    appid=SPARK_APP_ID,
    api_key=SPARK_API_KEY,
    api_secret=SPARK_API_SECRET,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ èµ„æºæ¨èåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ‰¾åˆ°ä¼˜è´¨çš„å­¦ä¹ èµ„æ–™ã€‚"
)

def fetch_url_content(url, timeout=5):
    """è·å–URLå†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯"""
    try:
        proxies = {
            "http": "http://127.0.0.1:7890",
            "https": "http://127.0.0.1:7890"
        }
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=timeout,proxies=proxies)
        response.raise_for_status()
        
        # æå–æ ‡é¢˜
        title_match = re.search(r'<title[^>]*>(.*?)</title>', response.text, re.IGNORECASE | re.DOTALL)
        title = title_match.group(1).strip() if title_match else "æœªçŸ¥æ ‡é¢˜"
        
        # æå–æè¿°
        desc_match = re.search(r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']*)["\']', response.text, re.IGNORECASE)
        description = desc_match.group(1).strip() if desc_match else ""
        
        # æå–æ­£æ–‡å†…å®¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        content = re.sub(r'<[^>]+>', '', response.text)
        content = re.sub(r'\s+', ' ', content).strip()
        content = content[:500]  # åªå–å‰500å­—ç¬¦
        
        return {
            'title': title,
            'description': description,
            'content': content,
            'url': url
        }
    except Exception as e:
        return {
            'title': f"æ— æ³•è®¿é—®: {url}",
            'description': f"è®¿é—®å¤±è´¥: {str(e)}",
            'content': "",
            'url': url
        }

def fetch_url_content_with_progress(args):
    """å¸¦è¿›åº¦æ˜¾ç¤ºçš„URLå†…å®¹è·å–å‡½æ•°"""
    url, index, total = args
    print(f"åˆ†æç¬¬ {index}/{total} ä¸ªé“¾æ¥: {url}")
    result = fetch_url_content(url)
    return result

def google_search_with_retry(query, max_results=10, max_retries=3):
    """ä½¿ç”¨Googleæœç´¢ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            print(f"Googleæœç´¢å°è¯• {attempt + 1}/{max_retries}...")
            results = []

            # ä½¿ç”¨google-search-pythonè¿›è¡Œæœç´¢
            search_query = f"{query} å­¦ä¹ æ•™ç¨‹ è§†é¢‘ è¯¾ç¨‹ åœ¨çº¿å­¦ä¹ "
            for url in search(search_query, num_results=max_results, lang="zh"):
                results.append(url)

            if results:
                return results[:15]  # è¿”å›å‰15ä¸ªç»“æœç”¨äºå†…å®¹åˆ†æ

        except Exception as e:
            print(f"Googleæœç´¢å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                print("ç­‰å¾… 3 ç§’åé‡è¯•...")
                time.sleep(3)
            else:
                print("Googleæœç´¢éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
                return []

    return []

# 4. å¤‡ç”¨æœç´¢ï¼ˆæ— æœç´¢æœåŠ¡æ—¶æä¾›å¸¸è§„å¹³å°ï¼‰
def fallback_search(keyword):
    return f"""âš ï¸ å½“å‰ç½‘ç»œç¯å¢ƒé™åˆ¶äº†æœç´¢æœåŠ¡ã€‚ä»¥ä¸‹æ˜¯å…³äº"{keyword}"çš„ä¸€äº›å¸¸è§å­¦ä¹ å¹³å°æ¨èï¼š

1. [æ…•è¯¾ç½‘](https://www.imooc.com) - æä¾›å¤§é‡ç¼–ç¨‹/èŒåœºç±»ä¸­æ–‡è¯¾ç¨‹
2. [å“”å“©å“”å“©](https://www.bilibili.com) - æœç´¢"{keyword} æ•™ç¨‹"è·å–è§†é¢‘èµ„æº
3. [Coursera](https://www.coursera.org) - æµ·é‡è‹±è¯­åœ¨çº¿å¤§å­¦è¯¾ç¨‹
4. [GitHub](https://github.com/search?q={keyword}) - æŸ¥æ‰¾ç›¸å…³å¼€æºå­¦ä¹ é¡¹ç›®
5. [Stack Overflow](https://stackoverflow.com/search?q={keyword}) - æœç´¢æŠ€æœ¯é—®ç­”
"""

def find_learning_resources(keyword):
    """æŸ¥æ‰¾å­¦ä¹ èµ„æºçš„ç®€å•ç‰ˆæœ¬"""
    print(f"æ­£åœ¨æœç´¢å…³äº '{keyword}' çš„å­¦ä¹ èµ„æº...")
    
    # 1. æœç´¢ç›¸å…³èµ„æºï¼ˆä½¿ç”¨Googleæœç´¢ï¼‰
    search_urls = google_search_with_retry(keyword)
    
    if not search_urls:
        print("æœç´¢å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
        fallback_result = fallback_search(keyword)
        print(f"\nã€å­¦ä¹ èµ„æºæ¨èã€‘\n{fallback_result}")
        return fallback_result
    
    print(f"æ‰¾åˆ° {len(search_urls)} ä¸ªæœç´¢ç»“æœï¼Œæ­£åœ¨å¹¶è¡Œåˆ†æå†…å®¹...")
    
    # 2. ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œè·å–æ¯ä¸ªURLçš„å†…å®¹ä¿¡æ¯
    url_contents = []
    
    # å‡†å¤‡å‚æ•°
    args_list = [(url, i+1, len(search_urls)) for i, url in enumerate(search_urls)]
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=4) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_url = {executor.submit(fetch_url_content_with_progress, args): args for args in args_list}
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_url):
            try:
                result = future.result()
                url_contents.append(result)
            except Exception as e:
                url, index, total = future_to_url[future]
                print(f"å¤„ç†é“¾æ¥ {index} æ—¶å‡ºé”™: {e}")
                url_contents.append({
                    'title': f"å¤„ç†å¤±è´¥: {url}",
                    'description': f"é”™è¯¯: {str(e)}",
                    'content': "",
                    'url': url
                })
    
    # 3. æ„å»ºè¯¦ç»†çš„åˆ†ææç¤ºï¼Œæä¾›å‚è€ƒä½†ä¸é™åˆ¶
    content_summary = ""
    valid_urls = []  # è®°å½•æœ‰æ•ˆçš„URL
    
    for i, content in enumerate(url_contents, 1):
        # åªå¤„ç†èƒ½æˆåŠŸè·å–å†…å®¹çš„é“¾æ¥
        if "æ— æ³•è®¿é—®" not in content['title'] and "å¤„ç†å¤±è´¥" not in content['title'] and content['content']:
            valid_urls.append(content['url'])
            content_summary += f"""
                é“¾æ¥ {len(valid_urls)}: {content['url']}
                æ ‡é¢˜: {content['title']}
                æè¿°: {content['description']}
                å†…å®¹æ‘˜è¦: {content['content'][:200]}...
                ---
            """
    
    print(f"æˆåŠŸåˆ†æ {len(valid_urls)} ä¸ªæœ‰æ•ˆé“¾æ¥ï¼Œæ­£åœ¨ç”Ÿæˆæ¨è...")
    
    # 4. è®©LLMåˆ†ææœç´¢ç»“æœå¹¶æ¨è
    analysis_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ èµ„æºæ¨èåŠ©æ‰‹ï¼Œå–„äºåˆ†ææœç´¢ç»“æœå¹¶å¯¹å­¦ä¹ èµ„æºè¿›è¡Œåˆ†ç±»æ•´ç†ã€‚

        è¯·æ ¹æ®ä»¥ä¸‹è¯¦ç»†çš„æœç´¢ç»“æœå†…å®¹ï¼Œå›´ç»•"{keyword}"è¿™ä¸€ä¸»é¢˜ï¼Œç­›é€‰å’Œåˆ†ç±»æ¨èé«˜è´¨é‡çš„å­¦ä¹ èµ„æºã€‚

        ğŸ”ã€æœç´¢ç»“æœå‚è€ƒã€‘ï¼š
        {content_summary}

        ğŸ“šã€æ¨èç­–ç•¥ã€‘ï¼š
        1. ä¼˜å…ˆæ¨èä¸Šé¢æœç´¢ç»“æœä¸­çš„ä¼˜è´¨èµ„æº
        2. ä½ ä¹Ÿå¯ä»¥æ¨èå…¶ä»–ä½ çŸ¥é“çš„ä¼˜è´¨å­¦ä¹ èµ„æºï¼Œä½†è¦ç¡®ä¿é“¾æ¥çœŸå®æœ‰æ•ˆ
        3. æ¨èçš„èµ„æºåº”è¯¥æ¶µç›–ä¸åŒçš„å­¦ä¹ å¹³å°å’Œå½¢å¼

        ğŸ“šã€ä½ çš„ä»»åŠ¡ã€‘ï¼š
        1. ä»”ç»†åˆ†ææ¯ä¸ªé“¾æ¥çš„å…·ä½“å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æè¿°å’Œå†…å®¹æ‘˜è¦
        2. å°†è¿™äº›èµ„æºåˆ’åˆ†åˆ°ä»¥ä¸‹ 3~4 ç±»ä¸­ï¼š
        - è§†é¢‘è¯¾ç¨‹ï¼ˆå¦‚ Bç«™ã€YouTubeã€è…¾è®¯è¯¾å ‚ã€Courseraç­‰ï¼‰
        - å­¦ä¹ æ–‡æ¡£ï¼ˆå¦‚ èœé¸Ÿæ•™ç¨‹ã€W3Schoolã€å®˜æ–¹æ–‡æ¡£ã€æ˜é‡‘ç­‰ï¼‰
        - å®æˆ˜é¡¹ç›® / å¼€æºä»£ç ï¼ˆå¦‚ GitHub é¡¹ç›®ã€æ•™ç¨‹ä»“åº“ï¼‰
        - å…¶ä»–æœ‰å¸®åŠ©çš„å­¦ä¹ å¹³å°æˆ–ç¤¾åŒº

        3. æ¯ä¸ªåˆ†ç±»ä¸‹æ¨è 3-6 ä¸ªèµ„æºï¼Œæ ¼å¼æ¸…æ™°ï¼Œé¿å…é‡å¤
        4. å¯¹æ¯ä¸ªèµ„æºçš„æè¿°è¦å…·ä½“ä¸”æœ‰ä»·å€¼

        ğŸ§  è¯·ä»¥ä»¥ä¸‹ **JSON æ ¼å¼** è¿”å›ï¼š

        {{
        "video_courses": [
            {{
            "name": "èµ„æºåç§°",
            "desc": "å…·ä½“è¯´æ˜è¿™ä¸ªèµ„æºçš„ç‰¹ç‚¹å’Œä»·å€¼",
            "url": "çœŸå®æœ‰æ•ˆçš„é“¾æ¥"
            }},
            ...
        ],
        "learning_docs": [...],
        "projects": [...],
        "other_platforms": [...]
        }}

        âš ï¸ æ³¨æ„ï¼š
        - ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«è§£æ
        - æ‰€æœ‰URLå¿…é¡»æ˜¯çœŸå®æœ‰æ•ˆçš„é“¾æ¥
        - æè¿°è¦å…·ä½“ï¼Œè¯´æ˜èµ„æºçš„ç‰¹ç‚¹å’Œé€‚ç”¨äººç¾¤
        - æ²¡æœ‰çš„åˆ†ç±»å¯ä»¥çœç•¥ï¼Œä½†ä¸è¦è¿”å› null
        - å¯ä»¥æ¨èæœç´¢ç»“æœä¹‹å¤–çš„ä¼˜è´¨èµ„æº

"""

    recommendations = search_chat.chat(analysis_prompt)
    
    # 5. éªŒè¯è¿”å›çš„é“¾æ¥å¹¶è¿‡æ»¤æ— æ•ˆé“¾æ¥
    try:
        # å°è¯•è§£æJSON
        if isinstance(recommendations, str):
            # æå–JSONéƒ¨åˆ†
            json_start = recommendations.find('{')
            json_end = recommendations.rfind('}') + 1
            if json_start != -1 and json_end != 0:
                json_str = recommendations[json_start:json_end]
                parsed_result = json.loads(json_str)
                
                # éªŒè¯æ‰€æœ‰URLå¹¶åˆ é™¤æ— æ•ˆçš„
                cleaned_result = {}
                total_removed = 0
                
                for category_name, category_items in parsed_result.items():
                    if isinstance(category_items, list):
                        cleaned_items = []
                        for item in category_items:
                            if isinstance(item, dict) and 'url' in item:
                                # æ£€æŸ¥URLæ˜¯å¦åœ¨æœ‰æ•ˆåˆ—è¡¨ä¸­ï¼ˆä¼˜å…ˆï¼‰æˆ–å°è¯•è®¿é—®éªŒè¯
                                if item['url'] in valid_urls:
                                    cleaned_items.append(item)
                                else:
                                    # å¯¹äºä¸åœ¨æœç´¢ç»“æœä¸­çš„é“¾æ¥ï¼Œå°è¯•å¿«é€ŸéªŒè¯
                                    try:
                                        response = requests.head(item['url'], timeout=3)
                                        if response.status_code == 200:
                                            cleaned_items.append(item)
                                        else:
                                            print(f"âš ï¸ åˆ é™¤æ— æ•ˆé“¾æ¥: {item['url']} (çŠ¶æ€ç : {response.status_code})")
                                            total_removed += 1
                                    except:
                                        print(f"âš ï¸ åˆ é™¤æ— æ•ˆé“¾æ¥: {item['url']} (æ— æ³•è®¿é—®)")
                                        total_removed += 1
                            else:
                                cleaned_items.append(item)
                        cleaned_result[category_name] = cleaned_items
                    else:
                        cleaned_result[category_name] = category_items
                
                if total_removed > 0:
                    print(f"å…±åˆ é™¤äº† {total_removed} ä¸ªæ— æ•ˆé“¾æ¥")
                
                # å°†æ¸…ç†åçš„ç»“æœè½¬æ¢å›JSONå­—ç¬¦ä¸²
                recommendations = json.dumps(cleaned_result, ensure_ascii=False, indent=2)
                
                return recommendations
            else:
                return recommendations
        else:
            return recommendations
    except json.JSONDecodeError:
        print("JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ")
        return recommendations

# 5. ä¸»ç¨‹åº
if __name__ == "__main__":
    keyword = input("è¯·è¾“å…¥ä½ è¦æŸ¥æ‰¾çš„å­¦ä¹ ä¸»é¢˜å…³é”®è¯ï¼š")
    result = find_learning_resources(keyword)
    print("\nã€å­¦ä¹ èµ„æºæ¨èã€‘\n", result) 