import os
from dotenv import load_dotenv
from joblib import load
# from src.utils.xfyun_chat import XFYunChat
# from src.utils.humewrapper import HumeSentimentAnalyzer
from src.utils.xfyun_chat import XFYunChat
# from src.utils.humewrapper import HumeSentimentAnalyzer
from src.modules import ConversationVerifier
import traceback
import json
from src.utils.sentime_analyse_new import generate_feedback, load_local_model
from transformers import BertTokenizer, BertForSequenceClassification
from src.modules.resume_optimizer import *
from src.utils.sentime_analyse_new import extract_emotion_series
from fer import FER

relate_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

# éŸ³é¢‘æ¨¡å‹åŠ è½½
save_dir = os.path.join(relate_path, r"model/chinese_emotion_model") # æœ¬åœ°æ¨¡å‹ç›®å½•
extractor, audio_model, classifier, config = load_local_model(save_dir)

# åˆå§‹åŒ– FER æ£€æµ‹å™¨
detector = FER(mtcnn=True)

class PostConversationProcessor:
    """Processes post-conversation data for candidate evaluation."""
    def __init__(self, path_name, pass_rate,model,tokenizer):
        """
        Initialize the PostConversationProcessor.

        Args:
            timestamp (str): Timestamp of the interview.
        """
        load_dotenv(os.path.join(os.path.dirname(os.getcwd()), ".env"))
        # self.timestamp = timestamp
        self.path_name = path_name
        self.pass_rate = str(pass_rate)
        interview_path = os.path.join(relate_path, 'data/interviews/')
        self.directory = os.path.join(interview_path, self.path_name)
        self.chatlog = load(os.path.join(self.directory, "joblib/conversation.joblib"))
        self.setup_models()
        self.sentiments = []
        self.output_files = []
        self.start_video_time = 0.0

        self.model = model
        self.tokenizer = tokenizer

    def setup_models(self):
        load_dotenv()
        """Set up the sentiment analyzer and AI models."""
        try:
            print('hume_apikey:',os.getenv("HUME_API_KEY"))
            # self.sentiment_analyser = HumeSentimentAnalyzer(api_key=os.getenv("HUME_API_KEY"))
            
            sentiment_system_prompt = """You are a skilled emotions analyst provided with a detailed breakdown of sentiment analysis scores from Hume.ai, for a single response in an interview to a question from the interviewer. The scores are split into 3 sections. All numbers are from 0 to 1, linearly scaling, with 1 being a very strong representation of the indicator in question.

            First, Emotions. This contains several human emotions with a numerical value indicating the strength of the corresponding emotion.
            Second, Sentiments. This contains a scale from 1 to 9, each containing a numerical value indicating the magnitude of the sentiment of the topic of the conversation. A negative topic such as murder will have a high value lower in the scale, such as 1 or 2, and a positive topic will have a high value from 0 to 1 higher in the scale such as 8 or 9.
            Third, Toxicity. This contains several toxic representations such as hate, insult, etc, with a value from 0 to 1 for each representation identified in the audio.

            Your job is to provide a concise detailed one sentence breakdown of how the individual was feeling for the particular scores provided. You must be highly objective as your job is to discern whether or not a candidate was exhibiting traits which would or would not be fitting for a successful interview. 
            Model your answer beginning with something along the lines of "For this particular response, the candidate...
            Your output must be in Chinese."""

           # æ›¿æ¢ sentiment_summariser
            self.sentiment_summariser = XFYunChat(
                appid=os.getenv("XFYUN_APPID"),
                api_key=os.getenv("XFYUN_API_KEY"),
                api_secret=os.getenv("XFYUN_API_SECRET"),
                system_prompt=sentiment_system_prompt
            )

            # evaluation_system_prompt = f"""
            # ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¼ä¸šæ‹›è˜é¡¾é—®ï¼Œè´Ÿè´£æ’°å†™å€™é€‰äººçš„é¢è¯•åé¦ˆã€‚è¯·ä»¥â€œ**æä¾›å»ºè®¾æ€§åé¦ˆã€é¼“åŠ±æˆé•¿**â€ä¸ºç›®æ ‡ï¼Œä¸ºå€™é€‰äººè¾“å‡ºä¸€ä»½**ä¸­æ–‡**çš„èƒ½åŠ›åˆ†ææŠ¥å‘Šã€‚
            #
            # ä½ å°†ä¼šæ”¶åˆ°ä»¥ä¸‹ä¿¡æ¯ï¼š
            # 1. å²—ä½æè¿°ï¼ˆJob Descriptionï¼‰
            # 2. é¢è¯•è½¬å½•æ–‡æœ¬ï¼ˆinterview transcriptï¼‰
            # 3. æƒ…ç»ªåˆ†æç»“æœï¼ˆå¦‚æœ‰ï¼‰
            # 4. å€™é€‰äººæ˜¯å¦æœ‰äº‹å®æ€§é”™è¯¯çš„åˆ†æï¼ˆå¦‚æœ‰ï¼‰
            # 5. å€™é€‰äººçš„ç®€å†
            #
            # âš ï¸ å¦‚æœéƒ¨åˆ†ä¿¡æ¯ç¼ºå¤±ï¼Œè¯·æ ¹æ®å¯ç”¨çš„å†…å®¹ï¼ˆå¦‚é¢è¯•æ–‡æœ¬å’Œç®€å†ï¼‰è¿›è¡Œè¯„ä¼°ã€‚
            #
            # ---
            #
            # è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºåé¦ˆå†…å®¹ï¼Œå…¨éƒ¨ä½¿ç”¨ä¸­æ–‡ï¼Œè¯­æ°”å‹å¥½ä½†å®¢è§‚ï¼š
            #
            # ---
            #
            # ### ğŸ§ ã€èƒ½åŠ›è¯„ä¼°ã€‘
            #
            # è¯·åˆ†åˆ«ä»ä»¥ä¸‹äº”ä¸ªç»´åº¦ï¼Œå¯¹å€™é€‰äººè¿›è¡Œ1~10åˆ†çš„æ‰“åˆ†ï¼Œå¹¶ç»“åˆé¢è¯•ä¸­çš„å…·ä½“å›ç­”ï¼Œè§£é‡Šè¯¥å¾—åˆ†çš„ä¾æ®ï¼š
            #
            # 1. **æ²Ÿé€šèƒ½åŠ›**ï¼ˆè¡¨è¾¾æ˜¯å¦æ¸…æ™°ã€æœ‰æ¡ç†ï¼‰
            # 2. **ä¸“ä¸šèƒ½åŠ›**ï¼ˆå²—ä½æ‰€éœ€æŠ€èƒ½ä¸ç»éªŒï¼‰
            # 3. **é—®é¢˜è§£å†³èƒ½åŠ›**ï¼ˆæ˜¯å¦èƒ½æ¸…æ™°åˆ†æã€æ‹†è§£é—®é¢˜ï¼‰
            # 4. **å·¥ä½œæ€åº¦ä¸ç§¯ææ€§**ï¼ˆè¡¨ç°å‡ºçš„çƒ­æƒ…ã€ä¸»åŠ¨æ€åº¦ï¼‰
            # 5. **å­¦ä¹ èƒ½åŠ›ä¸æˆé•¿æ½œåŠ›**ï¼ˆèƒ½å¦å¿«é€Ÿå­¦ä¹ ã€é€‚åº”å˜åŒ–ï¼‰
            #
            # æ¯é¡¹è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æè¿°ï¼š
            # - èƒ½åŠ›åç§°ï¼šX åˆ†  ï¼ˆæ•´æ•°ï¼ŒèŒƒå›´ä¸º 1~10ï¼‰
            # - ç®€è¦è¯„è¯­ï¼šä¸€å¥æ€»ä½“æ€»ç»“
            # - ç¤ºä¾‹åˆ†æï¼šå¼•ç”¨é¢è¯•ä¸­çš„å…·ä½“å›ç­”ï¼ˆè¯·ç”¨â€œä¾‹å¦‚ä»–æåˆ°...â€æˆ–â€œå½“è¢«é—®åŠ...â€çš„æ–¹å¼ï¼‰
            # - å¦‚å¾—åˆ† â‰¤ 8 åˆ†ï¼Œè¿˜è¯·è¡¥å……ï¼š
            #   - æ”¹è¿›å»ºè®®ï¼ˆå…·ä½“å¯è¡Œï¼‰
            #   - æ¨èå­¦ä¹ èµ„æ–™ï¼ˆå¦‚ä¹¦ç±ã€è¯¾ç¨‹ã€æ–¹æ³•ï¼‰
            #
            # ---
            #
            # ### ğŸ“ã€æ•´ä½“å»ºè®®ä¸ä¸‹ä¸€æ­¥ã€‘
            #
            # è¯·æ ¹æ®å€™é€‰äººæ•´ä½“è¡¨ç°ï¼Œåˆ¤æ–­æ˜¯å¦é€šè¿‡é¢è¯•ã€‚
            #
            # - è‹¥æ¨èé€šè¿‡ï¼Œè¯·è¯´æ˜å…¶ä¼˜åŠ¿ï¼Œä»¥åŠåœ¨å“ªäº›æ–¹é¢ä»æœ‰è¿›æ­¥ç©ºé—´
            # - è‹¥æš‚ä¸æ¨èï¼Œè¯·è¡¨è¾¾å§”å©‰ä½†æ¸…æ™°çš„æ‹’ç»ï¼Œå¹¶é¼“åŠ±å…¶æœªæ¥å‘å±•
            # - æœ€åç”¨ä¸€å¥ç®€çŸ­è¯ç»“å°¾é¼“åŠ±å€™é€‰äººç»§ç»­åŠªåŠ›
            #
            # ---
            #
            # ### âš ï¸ è¾“å‡ºæ ¼å¼å¿…é¡»ä¸ºä¸­æ–‡ï¼Œç»“æ„æ¸…æ™°ã€‚è¯·é¿å…ä½¿ç”¨è‹±è¯­ã€‚
            # """

            evaluation_system_prompt = """
            ä½ æ˜¯ä¸€ä½å…·å¤‡äººåŠ›èµ„æºèƒŒæ™¯ä¸é¢è¯•è¡Œä¸ºåˆ†æç»éªŒçš„æ™ºèƒ½è¯„ä¼°ä¸“å®¶ï¼Œç›®æ ‡æ˜¯æ ¹æ®å€™é€‰äººçš„**é¢è¯•è¡¨ç°**å’Œ**å²—ä½åŒ¹é…åº¦**ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„è¯„ä¼°åé¦ˆæŠ¥å‘Šã€‚

            ä½ çš„ä»»åŠ¡æ˜¯ï¼š
            - åŠ¨æ€è¯„ä¼°å€™é€‰äººå„é¡¹æ ¸å¿ƒèƒ½åŠ›ï¼Œç»™å‡ºé‡åŒ–è¯„åˆ†ï¼ˆ1~5åˆ†ï¼‰
            - æä¾›**èƒ½åŠ›é›·è¾¾å›¾**å¯è§†åŒ–æ”¯æŒæ•°æ®
            - ç»“åˆé¢è¯•é—®ç­”å†…å®¹ï¼Œå®šä½å…³é”®é—®é¢˜ï¼Œç»™å‡º**ç»“æ„åŒ–æ”¹è¿›å»ºè®®**
            - æ ¹æ®æ•´ä½“è¡¨ç°ï¼Œè®¡ç®—ä¸€ä¸ªæ»¡åˆ†ä¸º100åˆ†çš„æ€»è¯„åˆ†ï¼Œå¹¶åšå‡ºæœ€ç»ˆæ¨èåˆ¤æ–­

            ---

            ã€è¯„åˆ†æ ‡å‡†è¯´æ˜ã€‘ï¼ˆæ‰€æœ‰å•é¡¹èƒ½åŠ›è¯„åˆ†ç»Ÿä¸€ä½¿ç”¨ 1ï½5 åˆ†ï¼‰ï¼š
            - 5åˆ†ï¼šè¡¨ç°éå¸¸å‡ºè‰²ï¼Œè¿œè¶…å²—ä½é¢„æœŸï¼Œæœ‰æ¸…æ™°è¯æ®æ”¯æŒ
            - 4åˆ†ï¼šè¡¨ç°è‰¯å¥½ï¼Œè¾¾åˆ°å²—ä½è¦æ±‚ï¼Œå¶æœ‰å°ç¼ºé™·
            - 3åˆ†ï¼šåŸºæœ¬ç¬¦åˆè¦æ±‚ï¼Œå­˜åœ¨å¯æ”¹å–„ç©ºé—´
            - 2åˆ†ï¼šç•¥ä½äºå²—ä½è¦æ±‚ï¼Œèƒ½åŠ›ä¸è¶³è¾ƒæ˜æ˜¾
            - 1åˆ†ï¼šè¿œæœªè¾¾æ ‡ï¼Œè¡¨ç°å­˜åœ¨è¾ƒå¤§çŸ­æ¿

            ã€æ€»è¯„åˆ†è¯´æ˜ã€‘ï¼š
            è¯·ç»¼åˆå„é¡¹èƒ½åŠ›è¯„åˆ†ã€å²—ä½åŒ¹é…åº¦ã€æƒ…ç»ªç¨³å®šæ€§ç­‰ç»´åº¦ï¼Œç»™å‡ºä¸€ä¸ªæ€»è¯„åˆ†ï¼ˆ0~100åˆ†ï¼‰ï¼š
            - â‰¥85ï¼šä¼˜ç§€ï¼Œå¼ºçƒˆæ¨è
            - 70~84ï¼šè‰¯å¥½ï¼Œå¯æ¨è
            - 60~69ï¼šä¸€èˆ¬ï¼Œä¿ç•™è§‚å¯Ÿ
            - ï¼œ60ï¼šè¾ƒå¼±ï¼Œä¸å»ºè®®å½•ç”¨

            ---

            ã€è¾“å…¥å†…å®¹ã€‘ï¼ˆä¸¤ä¸ªï¼‰ï¼š
            1. `chatlog`ï¼šé¢è¯•è¿‡ç¨‹ç»“æ„åŒ–ä¿¡æ¯ï¼ŒåŒ…å«ï¼š
               - é¢è¯•é—®é¢˜ä¸å€™é€‰äººå›ç­”å†…å®¹
               - å‡†ç¡®æ€§åˆ†æï¼ˆå¦‚ï¼šå›ç­”å‡†ç¡®ç‡ã€æŠ€æœ¯ç‚¹è¦†ç›–ã€å»ºè®®ï¼‰
               - æƒ…ç»ªåˆ†æï¼ˆå¦‚â€œç´§å¼ ä½†è¡¨è¾¾æ¸…æ™°â€ï¼‰
            2. `job_resume_eval`ï¼šå²—ä½åŒ¹é…åº¦ä¸ç®€å†åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
               - æŠ€èƒ½åŒ¹é…åº¦ã€ç»éªŒåŒ¹é…åº¦ã€å‘å±•å¥‘åˆåº¦è¯„åˆ†ä¸å»ºè®®
               - æ˜¯å¦æ¨èã€ç†ç”±ã€ç®€å†ä¼˜åŒ–å»ºè®®

            ---

            ã€è¾“å‡ºè¦æ±‚ã€‘ï¼šè¯·ä½¿ç”¨å¦‚ä¸‹ JSON æ ¼å¼è¾“å‡ºç»“æ„åŒ–åé¦ˆï¼Œå­—æ®µè¯´æ˜å¦‚ä¸‹ï¼š

            ```json
            {
              "ability_scores": {
                "ä¸“ä¸šçŸ¥è¯†æ°´å¹³": {"score": 4, "evidence": "åœ¨è¢«é—®åŠSpringæ¡†æ¶æ—¶å›ç­”å‡†ç¡®ï¼Œä½†æœªæåŠIOCæœºåˆ¶" },
                "æŠ€èƒ½åŒ¹é…åº¦": {"score": 3, "evidence": "å…·å¤‡å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼Œä½†ç¼ºå°‘DevOpsç›¸å…³ç»éªŒ" },
                "è¯­è¨€è¡¨è¾¾èƒ½åŠ›": {"score": 4, "evidence": "å›ç­”æµç•…ï¼Œé€»è¾‘æ¸…æ™°ï¼Œæœ‰è¾ƒå¼ºè¯´æœåŠ›" },
                "é€»è¾‘æ€ç»´èƒ½åŠ›": {"score": 2, "evidence": "åœ¨æ‹†è§£å¤æ‚é—®é¢˜æ—¶ç¼ºä¹å±‚æ¬¡æ„Ÿï¼Œè¡¨è¾¾ç•¥æ˜¾è·³è·ƒ" },
                "åº”å˜ä¸æŠ—å‹èƒ½åŠ›": {"score": 3, "evidence": "é¢å¯¹è¿½é—®æ—¶åº”å¯¹è¾ƒå¥½ï¼Œæƒ…ç»ªä¿æŒç¨³å®š" }
              },
              "radar_data": {
                "ä¸“ä¸šçŸ¥è¯†æ°´å¹³": 4,
                "æŠ€èƒ½åŒ¹é…åº¦": 3,
                "è¯­è¨€è¡¨è¾¾èƒ½åŠ›": 4,
                "é€»è¾‘æ€ç»´èƒ½åŠ›": 2,
                "åº”å˜ä¸æŠ—å‹èƒ½åŠ›": 3
              },
              "problem_insights": [
                {
                  "dimension": "è¡¨è¾¾ç»“æ„",
                  "issue": "éƒ¨åˆ†å›ç­”ç¼ºä¹æ¡ç†ï¼Œæœªä½¿ç”¨ç»“æ„åŒ–è¡¨è¾¾",
                  "suggestion": "å»ºè®®ä½¿ç”¨ STAR æ–¹æ³•æˆ–æ€»åˆ†æ€»ç»“æ„ï¼Œæå‡è¡¨è¾¾æ¸…æ™°åº¦"
                },
                {
                  "dimension": "é€»è¾‘æ€ç»´èƒ½åŠ›",
                  "issue": "é¢å¯¹å¤æ‚é—®é¢˜æ‹†è§£èƒ½åŠ›ä¸è¶³ï¼Œç¼ºä¹ç³»ç»Ÿæ€§",
                  "suggestion": "ç»ƒä¹ é—®é¢˜åˆ†æä¸è¦ç‚¹æç‚¼ï¼Œæå‡æ¡ç†æ€§"
                },
                {
                  "dimension": "åº”å˜ä¸æŠ—å‹èƒ½åŠ›",
                  "issue": "é¢å¯¹è¿½é—®æ—¶ç•¥æ˜¾ç´§å¼ ï¼Œå›ç­”æµç•…åº¦å—å½±å“",
                  "suggestion": "å¢å¼ºå¿ƒç†ç´ è´¨è®­ç»ƒï¼Œæé«˜ç°åœºåº”å˜èƒ½åŠ›"
                },
                {
                  "dimension": "ä¸“ä¸šçŸ¥è¯†æ°´å¹³",
                  "issue": "éƒ¨åˆ†æŠ€æœ¯ç»†èŠ‚å›ç­”ä¸å¤Ÿå‡†ç¡®æˆ–å®Œæ•´",
                  "suggestion": "åŠ å¼ºç›¸å…³æŠ€æœ¯ç†è®ºå­¦ä¹ ï¼Œæ³¨é‡çŸ¥è¯†ç‚¹è¡¥å……"
                },
                {
                  "dimension": "æŠ€èƒ½åŒ¹é…åº¦",
                  "issue": "ç¼ºå°‘éƒ¨åˆ†å²—ä½æ ¸å¿ƒæŠ€èƒ½çš„å®é™…ç»éªŒ",
                  "suggestion": "é’ˆå¯¹å²—ä½æŠ€èƒ½éœ€æ±‚ï¼Œå‚ä¸ç›¸å…³é¡¹ç›®ç§¯ç´¯ç»éªŒ"
                }
              ],
              "overall_recommendation": {
                "decision": "å»ºè®®é€šè¿‡ / ä¿ç•™è§‚å¯Ÿ / æš‚ä¸æ¨è",
                "reasoning": "å€™é€‰äººè¡¨ç°ç§¯æï¼Œä¸“ä¸šèƒ½åŠ›åŸºæœ¬è¾¾æ ‡ï¼Œè¡¨è¾¾è¾ƒå¥½ï¼Œä½†åœ¨é—®é¢˜æ‹†è§£æ·±åº¦ä¸Šæœ‰æå‡ç©ºé—´",
                "total_score": 78,
                "closing_remark": "è¯·ä¿æŒå­¦ä¹ çŠ¶æ€ï¼Œç›¸ä¿¡ä½ èƒ½åœ¨æœªæ¥å²—ä½ä¸­ä¸æ–­æˆé•¿ï¼"
              }
            }
            ```
            """

            cv_path = next((f for f in os.listdir(os.path.join(relate_path, "data/cvs")) if "active" in f), None)
            if cv_path is None:
                raise FileNotFoundError("No active CV file found in the 'data/cvs' directory.")
            cv_path = os.path.join(relate_path, "data/cvs", cv_path)
            # self.candidate_evaluator = ClaudeChatAssess("claude-3-5-sonnet-20240620", evaluation_system_prompt, cv_path)
            # æ›¿æ¢ candidate_evaluator
            self.candidate_evaluator = XFYunChat(
                appid=os.getenv("XFYUN_APPID"),
                api_key=os.getenv("XFYUN_API_KEY"),
                api_secret=os.getenv("XFYUN_API_SECRET"),
                system_prompt=evaluation_system_prompt,
                cv_path=cv_path  # æ·»åŠ CVè·¯å¾„
            )
        except Exception as e:
            print(f"An error occurred during model setup: {e}")
            raise

    def reformat_chatlog(self):
        """
        Reformat the chatlog into a list of dictionaries.

        Returns:
            list: Reformatted chatlog.
        """
        dropped_context = self.chatlog[2:]
        outputchatlog = []

        for i in range(0, len(dropped_context), 2):
            if i + 1 < len(dropped_context):
                tempdict = {
                    'interviewer': dropped_context[i]['content'],
                    'candidate': dropped_context[i+1]['content']
                }
                outputchatlog.append(tempdict)
            else:
                break 

        return outputchatlog

    def rename_file_remove_active(self,filepath, filename):
        if "-active" not in filename:
            return filename  # ä¸åŒ…å«activeï¼Œä¸æ”¹å
        new_name = filename.replace("-active", "")
        old_path = os.path.join(filepath, filename)
        new_path = os.path.join(filepath, new_name)
        if os.path.exists(new_path):
            print(f"è­¦å‘Šï¼šç›®æ ‡æ–‡ä»¶ {new_path} å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å‘½å")
            return new_path
        if not os.path.exists(old_path):
            return filename
        os.rename(old_path, new_path)
        return new_name

    def process_sentiments(self,  sentiments=None):
        """
        Process sentiments for each audio file in the chatlog.

        Args:
            chatlog_chat (list): The reformatted chatlog.

        Returns:
            list: Chatlog with added sentiment analysis.
        """
        path = os.path.join(relate_path, 'data/interviews/')
        filepath = os.path.join(path, str(self.path_name), 'audio')
        print(f"Current working directory: {os.getcwd()}")
        print(f"Full audio directory path: {os.path.abspath(filepath)}")

        files = [f for f in os.listdir(filepath) if os.path.isfile(os.path.join(filepath, f))]
        
        # if len(chatlog_chat) < len(files):
        #     files = files[:len(chatlog_chat)]

        for f in files:
            print(f"File found: {f}")

        for count, file in enumerate(files, 1):
            if "-active" not in file:
                print(f"Skipping file {file} as it does not contain '-active'")
                continue
            full_file_path = os.path.join(filepath, file)
            print(f"Processing file: {full_file_path}")

            # è§†é¢‘è·¯å¾„æ¨æµ‹ï¼ˆå¯æ ¹æ®ä½ çš„å‘½åè§„åˆ™è°ƒæ•´ï¼‰
            video_path = os.path.join(os.path.dirname(filepath),'video',file.replace('.wav','.mp4'))
            audio_path = full_file_path
            output_file = os.path.join(os.path.dirname(filepath),'emotion_time_series',file.replace('.wav','.json'))
            self.output_files.append(output_file)
            text_path = os.path.join(os.path.dirname(filepath), 'text', file.replace('.wav', '.txt'))
            text = open(text_path, 'r',encoding='utf-8').read()
            print(f"Text: {text}")

            try:
                # è°ƒç”¨ä½ è‡ªå·±çš„èåˆæƒ…ç»ªåˆ†æå‡½æ•°
                result = generate_feedback(self.model,self.tokenizer,audio_path, video_path, text)
                sentiment_summary = self.sentiment_summariser.chat(str(result))
                print(f"Sentiment Summary: {sentiment_summary}")
                sentiments.append(sentiment_summary)

                # é‡å‘½åéŸ³é¢‘æ–‡ä»¶
                new_audio_file = self.rename_file_remove_active(filepath, file)
                # é‡å‘½åè§†é¢‘æ–‡ä»¶
                new_video_file = self.rename_file_remove_active(os.path.join(os.path.dirname(filepath), 'video'),
                                                           file.replace('.wav', '.mp4'))
                # é‡å‘½åæ–‡æœ¬æ–‡ä»¶
                new_text_file = self.rename_file_remove_active(os.path.join(os.path.dirname(filepath), 'text'),
                                                          file.replace('.wav', '.txt'))

                new_video_path = os.path.join(relate_path, 'data/interviews', self.path_name, "video" ,new_video_file)
                new_audio_path = os.path.join(relate_path, 'data/interviews', self.path_name, "audio" , new_audio_file)
                output_path = os.path.join(relate_path, 'data/interviews', self.path_name, 'emotion_time_series/emotion.json')

                if os.path.exists(new_video_path):
                    print("start_video_time", self.start_video_time)
                    _, self.start_video_time = extract_emotion_series(
                        detector=detector,
                        video_path=new_video_path,
                        audio_path=new_audio_path,
                        extractor=extractor,
                        model=audio_model,
                        classifier=classifier,
                        config=config,
                        interval_sec=2.0,
                        use_video= True,
                        output_json_path=output_path,
                        start_video_time=self.start_video_time,
                    )
                else:
                    _, self.start_video_time = extract_emotion_series(
                        detector=detector,
                        video_path=new_video_path,
                        audio_path=new_audio_path,
                        extractor=extractor,
                        model=audio_model,
                        classifier=classifier,
                        config=config,
                        interval_sec=2.0,
                        use_video=False,
                        output_json_path=output_path,
                        start_video_time=self.start_video_time,
                    )

                # sentiments.append((result, sentiment_summary))

                # æ·»åŠ åˆ° chatlog
                # chatlog_chat[count - 1]['sentiment'] = sentiment_summary

            except Exception as e:
                sentiment_summary = "Error processing file"
                sentiments.append(sentiment_summary)
                print(f"Error processing file {full_file_path}: {str(e)}")
                traceback.print_exc()

        # for count, file in enumerate(files, 1):
        #     full_file_path = os.path.join(filepath, file)
        #     print(f"Processing file: {full_file_path}")
        #
        #     # Add a small delay and re-check file existence
        #     time.sleep(0.1)
        #     if not os.path.exists(full_file_path):
        #         print(f"File not found (after delay): {full_file_path}")
        #         continue
        #
        #     try:
        #         result = self.sentiment_analyser.analyze_audio(full_file_path)
        #         sentiment_summary = self.sentiment_summariser.chat(str(result))
        #         sentiments.append((result, sentiment_summary))
        #         chatlog_chat[count-1]['sentiment'] = sentiment_summary
        #     except Exception as e:
        #         print(f"Error processing file {full_file_path}: {str(e)}")
        #         traceback.print_exc()
        #
        # self.chatlog_chat = chatlog_chat

    def save_sentiments(self, chatlog_chat, sentiments):
        print("sentiments:",len(sentiments))
        print("chatlog:",len(chatlog_chat))
        if len(chatlog_chat) != len(sentiments):
            print("Warning: Number of chat log entries and sentiments do not match.")
            return
        if not sentiments:
            print("No sentiments to save.")
            return
        for i in range(len(chatlog_chat)):
            chatlog_chat[i]['sentiment'] = sentiments[i]

    def save_feedbacks(self, chatlog_chat, feedbacks):
        print("chatlog:",len(chatlog_chat))
        print("feedbacks:",len(feedbacks))
        print(feedbacks)
        if len(chatlog_chat) != len(feedbacks):
            print("Warning: Number of chat log entries and feedbacks do not match.")
            return
        if not feedbacks:
            print("No feedbacks to save.")
            return
        for i in range(len(chatlog_chat)):
            chatlog_chat[i]['feedback'] = feedbacks[i]

    def evaluate_candidate(self, chatlog_chat,advice):
        """
        Evaluate the candidate based on the chatlog and sentiment analysis.

        Args:
            chatlog_chat (list): The chatlog with sentiment analysis.

        Returns:
            str: Evaluation result.
        """
        # åˆ†ææ¯ä¸ªé—®ç­”å¯¹
        # ConversationVerifier.process_qa_pair(chatlog_chat)
        # ConversationVerifier.process_qa_pair(chatlog_chat)   # chatlog_chat æ˜¯ä¸€ä¸ª listï¼Œå®ƒåœ¨å‡½æ•°é‡Œè¢«å°±åœ°ä¿®æ”¹äº†ã€‚
        # print("The Feedback JSON from the sentiment analyser and accuracy verifier: \n")
        # print(chatlog_chat)

        input_data = {
            "chatlog": json.dumps(chatlog_chat, ensure_ascii=False, indent=2),
            "job_resume_eval": json.dumps(advice, ensure_ascii=False, indent=2)
        }

        full_prompt = f"""
        è¯·æ ¹æ®ä»¥ä¸‹å€™é€‰äººé¢è¯•è¡¨ç°å’Œå²—ä½åŒ¹é…è¯„ä¼°ï¼Œç”Ÿæˆç»“æ„åŒ–åé¦ˆï¼š

        ã€é¢è¯•è®°å½•ã€‘
        {chatlog_chat}

        ã€å²—ä½åŒ¹é…åˆ†æã€‘
        {advice}
        """

        evaluation = self.candidate_evaluator.chat(full_prompt)
        # evaluation = self.candidate_evaluator.chat(str(chatlog_chat))
        chatlog_file_path = os.path.join(relate_path, f"data/interviews/{self.path_name}/outcome/")
        # Save outcome to file for convinience
        if not os.path.exists(chatlog_file_path):
            os.makedirs(chatlog_file_path)
        with open(chatlog_file_path+"chatlog.json", "w",encoding="utf-8") as file:
            json.dump(chatlog_chat, file, indent=4,ensure_ascii=False)
            # json.dump(chatlog_chat, file, indent=4)
        evaluation_file_path = os.path.join(relate_path, f"data/interviews/{self.path_name}/outcome/")
        if not os.path.exists(chatlog_file_path):
            os.makedirs(chatlog_file_path)
        with open(evaluation_file_path+"evaluation.json", "w",encoding="utf-8") as file:
            file.write(str(evaluation).replace('```json', '').replace('```', '').replace("\\n", "\n"))
            return str(evaluation).replace('```json', '').replace('```', '').replace("\\n", "\n")

    def run(self,feedbacks,advice):
        """
        Run the post-conversation processing pipeline.

        Returns:
            str: Final evaluation of the candidate.
        """
        # # å¿…é¡»å…ˆå¤„ç†æƒ…æ„Ÿåˆ†æï¼Œæ‰€æœ‰å¤„ç†å®Œæˆåå†ä¿å­˜æƒ…æ„Ÿåˆ†æç»“æœ
        # sentiments = []
        # self.process_sentiments(sentiments)

        chatlog_chat = self.reformat_chatlog()
        self.save_feedbacks(chatlog_chat, feedbacks)
        # self.save_sentiments(chatlog_chat, sentiments)
        evaluation = self.evaluate_candidate(chatlog_chat,advice)
        print("------------------Evaluation----------------------")
        print(evaluation)
        return evaluation

    def handle_sentiments(self):
        self.process_sentiments(self.sentiments)

    def end_sentiments(self, feedbacks, advice, type):
        self.chatlog = load(os.path.join(self.directory, "joblib/conversation.joblib"))
        chatlog_chat = self.reformat_chatlog()
        self.save_feedbacks(chatlog_chat, feedbacks[1:])
        if type == "video":
            self.save_sentiments(chatlog_chat, self.sentiments[1:])
        evaluation = self.evaluate_candidate(chatlog_chat,advice)
        print("------------------Evaluation----------------------")
        print(evaluation)
        return evaluation

if __name__ == "__main__":
    model_path = os.path.join(relate_path, r'model/roberta-jd')
    tokenizer = BertTokenizer.from_pretrained(model_path)
    model = BertForSequenceClassification.from_pretrained(model_path)

    name = "æ¨ç’é›¨"
    json_path = r"data/cvs/cv-deb-active.pdf"
    # cv_json = parse_resume(json_path)
    # print(cv_json)
    role = "å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ"
    job_description = """
        èŒä½è¦æ±‚ï¼š
    1ï¼ç†Ÿæ‚‰ HTTP åè®®ã€æµè§ˆå™¨æ¸²æŸ“åŸç†
    2ï¼ç†Ÿæ‚‰HTML5/CSS3/JavaScriptï¼Œäº†è§£ES6ï¼‹æ–°ç‰¹æ€§
    3ï¼ç†Ÿæ‚‰ React / Vue ç­‰å¸¸ç”¨å‰ç«¯æ¡†æ¶ï¼Œç†Ÿç»ƒä½¿ç”¨ Tailwind CSS å’Œ TypeScript 
    4ï¼ç†Ÿæ‚‰ Vite ç­‰æ„å»ºå·¥å…·ï¼Œç†Ÿæ‚‰ NPM / Yarn åŒ…ç®¡ç†
    5.ç†Ÿç»ƒä½¿ç”¨ Git è¿›è¡Œç‰ˆæœ¬æ§åˆ¶
    åŠ åˆ†é¡¹ï¼š
    1.ç†Ÿæ‚‰ Golang Gin Web åç«¯æ¡†æ¶å¼€å‘ä¼˜å…ˆ
    2.ç†Ÿæ‚‰ Flutter è·¨ç«¯å¼€å‘å·¥å…·è€…ä¼˜å…ˆ
        """
    # ç®€å†åŒ¹é…åˆ†æ
    # optimizer = ResumeOptimizer(role, job_description)
    # advice = optimizer.optimize_resume(cv_json,name)
    with open(r'../../data/cvs/cv-niranj-feedback.json', 'r', encoding='utf-8') as f:
        advice = json.load(f)

    feedbacks = ['ã€å‡†ç¡®ç‡ã€‘ï¼š30%\n\nã€åé¦ˆã€‘ï¼šå€™é€‰äººä»…æåˆ°å»å™ªå¤„ç†ï¼Œä½†æœªå…·ä½“è¯´æ˜é‡‡ç”¨çš„æ–¹æ³•ï¼ˆå¦‚é«˜æ–¯æ»¤æ³¢ã€ä¸­å€¼æ»¤æ³¢ç­‰ï¼‰ï¼Œä¹Ÿæœªæ¶‰åŠå¦‚ä½•å¤„ç†ä¸å®Œæ•´ç›®æ ‡çš„å…³é”®æ­¥éª¤ï¼ˆå¦‚å½¢æ€å­¦æ“ä½œæˆ–ç›®æ ‡é‡å»ºç®—æ³•ï¼‰ã€‚å›ç­”è¿‡äºç®€ç•¥ä¸”ç¼ºä¹æŠ€æœ¯ç»†èŠ‚æ”¯æ’‘ã€‚\n\nã€æ”¹è¿›å»ºè®®ã€‘ï¼š\nâ€“ æ˜ç¡®è¯´æ˜å…·ä½“çš„å»å™ªæ–¹æ³•ï¼ˆä¾‹å¦‚ï¼šä½¿ç”¨é«˜æ–¯æ»¤æ³¢å»é™¤é«˜æ–¯å™ªå£°ï¼Œæˆ–ç”¨ä¸­å€¼æ»¤æ³¢æŠ‘åˆ¶æ¤’ç›å™ªå£°ï¼‰\nâ€“ è¡¥å……é’ˆå¯¹ä¸å®Œæ•´ç›®æ ‡çš„å¤„ç†æ–¹æ³•ï¼ˆä¾‹å¦‚ï¼šé€šè¿‡å½¢æ€å­¦é—­è¿ç®—å¡«å……ç›®æ ‡ç©ºæ´ï¼Œæˆ–åŸºäºè½®å»“åŒ¹é…é‡å»ºç›®æ ‡è¾¹ç•Œï¼‰\nâ€“ å¯ç®€è¦æåŠå‚æ•°é€‰æ‹©ä¾æ®ï¼ˆå¦‚æ»¤æ³¢æ ¸å¤§å°ä¸ç›®æ ‡å°ºå¯¸çš„å…³ç³»ï¼‰',
                 'ã€å‡†ç¡®ç‡ã€‘ï¼š40%\n\nã€åé¦ˆã€‘ï¼šå€™é€‰äººä»…åˆ—ä¸¾äº†ä¸¤ç§åŸºç¡€å»å™ªæ–¹æ³•ï¼ˆå¹³æ»‘æ»¤æ³¢ã€é«˜æ–¯æ»¤æ³¢ï¼‰ï¼Œä½†æœªè¯´æ˜å…·ä½“å®ç°åŸç†å’Œé€‚ç”¨åœºæ™¯ã€‚å›ç­”ç¼ºä¹å¯¹å…¶ä»–é‡è¦å»å™ªæ–¹æ³•çš„è¦†ç›–ï¼Œä¸”æœªä½“ç°åˆ†ç±»è®¨è®ºå™ªå£°ç±»å‹ï¼ˆå¦‚æ¤’ç›å™ªå£°ã€é«˜æ–¯å™ªå£°ï¼‰çš„é’ˆå¯¹æ€§å¤„ç†æ€è·¯ã€‚\n\nã€æ”¹è¿›å»ºè®®ã€‘ï¼š\nâ€“ è¡¥å……ä¸åŒå™ªå£°ç±»å‹çš„å¯¹åº”å¤„ç†æ–¹æ³•ï¼ˆå¦‚ä¸­å€¼æ»¤æ³¢é’ˆå¯¹æ¤’ç›å™ªå£°ï¼‰\nâ€“ å¢åŠ é¢‘åŸŸå»å™ªæ–¹æ³•ï¼ˆå¦‚å‚…é‡Œå¶å˜æ¢åæ»¤æ³¢ï¼‰\nâ€“ è¯´æ˜è‡ªé€‚åº”æ»¤æ³¢ï¼ˆå¦‚éå±€éƒ¨å‡å€¼å»å™ªï¼‰æˆ–æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚DnCNNï¼‰\nâ€“ ç®€è¦æ¯”è¾ƒå„æ–¹æ³•ä¼˜ç¼ºç‚¹åŠé€‚ç”¨æ¡ä»¶']


    processor = PostConversationProcessor("Dawn/202507042024",0.47,model,tokenizer)
    # processor.end_sentiments(feedbacks,advice)
